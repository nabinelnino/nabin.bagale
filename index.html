<!DOCTYPE html>
<!--
	Canvas by TEMPLATE STOCK
	templatestock.co @templatestock
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <meta name="author" content="">
  <title>Nabin Bagale | Portfolio</title>

  <!-- =============== Bootstrap Core CSS =============== -->
  <link rel="stylesheet" href="css/bootstrap.min.css" type="text/css">
  <!-- =============== Google fonts =============== -->
  <link href='https://fonts.googleapis.com/css?family=Oswald:400,300' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,600' rel='stylesheet' type='text/css'>
  <!-- =============== fonts awesome =============== -->
  <link rel="stylesheet" href="css/font-awesome.min.css" type="text/css">
  <!-- =============== Plugin CSS =============== -->
  <link rel="stylesheet" href="css/animate.min.css" type="text/css">
  <!-- =============== Custom CSS =============== -->
  <link rel="stylesheet" href="css/style.css" type="text/css">
  <!-- =============== Owl Carousel Assets =============== -->
  <link href="owl-carousel/owl.carousel.css" rel="stylesheet">
  <link href="owl-carousel/owl.theme.css" rel="stylesheet">
  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->
</head>

<body>
  <!-- =============== Preloader =============== -->
  <div id="preloader">
    <div id="loading">
    </div>
  </div>
  <!-- =============== nav =============== -->
  <nav id="mainNav" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
            data-target="#bs-example-navbar-collapse-1">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="#"><img src="img/nabin_new.JPG" alt="Logo">
          </a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->

        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
          <ul class="nav navbar-nav navbar-right">
            <li>
              <a class="page-scroll" href="#about">About</a>
            </li>
            <li>
              <a class="page-scroll" href="#Projects">Projects</a>
            </li>
            <li>
              <a class="page-scroll" href="https://www.linkedin.com/in/nabin-bagale-b6433399" target="_blank"
                rel="noopener noreferrer">Linkdin</a>
            </li>
            <li>
              <a class="page-scroll" href="https://github.com/nabinelnino" target="_blank"
                rel="noopener noreferrer">GitHub</a>
            </li>
            <li>
              <a class="page-scroll" href="#Blogs" target="_blank" rel="noopener noreferrer">Blogs</a>
            </li>
            <!-- <li>
                            <a class="page-scroll" href="#Price">Price</a>
                        </li> -->
            <!-- <li>
                            <a class="page-scroll" href="#contact">Contact</a>
                        </li> -->
          </ul>
        </div>
        <!-- =============== navbar-collapse =============== -->

      </div>
    </div>
    <!-- =============== container-fluid =============== -->
  </nav>
  <!-- =============== header =============== -->
  <header>
    <!-- =============== container =============== -->
    <div class="container">
      <div class="header-content row">
        <div class="row">
          <h3> A passionate data analyst, data scientist and a software developer. I can translate business data into
            valuable <br>
            and comprehensible insights so as to improve results and to ease decision making procedure.</h3>
        </div>
        <div class="col-xs-12 col-sm-5 col-md-5">
          <h2 class="wow bounceIn animated" data-wow-delay=".40s">EDUCATION</h2>
          <div class="list-group">
            <a href="#" class="list-group-item active" style="font-size: large;">
              Post Graduate in Data Analytics for Business
            </a>
            <a href="#" class="list-group-item"></i><i class="fa fa-check-circle" aria-hidden="true"></i>
              St. Clair College, Windsor, ON, Canada (Jan 2021 - Present)</a>

          </div>

          <div class="list-group">
            <a href="#" class="list-group-item active" style="font-size: large; background-color: #87b733;">
              Bachelor in Computer Science and Information Technology
            </a>
            <a href="#" class="list-group-item"></i><i class="fa fa-check-circle" aria-hidden="true"></i>
              Tribhuvan University, Kathmandu, Nepal (2014- 2018)</a>

          </div>
        </div>
        <div class="col-xs-12 col-sm-7 col-md-7 wow slideInLeft animated">
          <img src="img/display.jpg" alt="phones" />
        </div>
      </div>
    </div>
    <!-- =============== container end =============== -->
  </header>
  <!-- =============== About =============== -->
  <section id="about" class="">
    <!-- =============== container =============== -->
    <div class="container">
      <span class="angle2"></span>
      <span class="angle"></span>
      <div class="row">
        <div class="col-xs-12 col-sm-5 col-md-4 wow fadeInLeft animated" data-wow-delay=".5s">
          <h1><span>About</span> </h2>
            <div class="margin-bottom-default">
              <ul>
                <li>
                  <h2 class=" margin-bottom-small">Field Of Interest</h2>
                </li>
                <div class="margin-bottom-large" style="margin: auto;padding:5px; font-size: large;"><span>Data Science
                    & Analytics</span></div>
                <div class="margin-bottom-small" style="margin: auto;padding:5px; font-size: large;"><span>Machine
                    Learning</span></div>
                <div class="margin-bottom-small" style="margin: auto;padding:5px; font-size: large;"><span>Deep
                    Learning</span></div>
                <div class="margin-bottom-small" style="margin: auto;padding:5px; font-size: large;"><span>Database
                    Development</span></div>

                <div class="margin-bottom-small" style="margin: auto;padding:5px; font-size: large;"><span>Computer
                    Vision</span></div>
                <div class="margin-bottom-small" style="margin: auto;padding:5px; font-size: large;"><span>Software
                    Development</span></div>
                <li>
                  <h2 class=" margin-bottom-small">Profile</h2>

                </li>
                <div class="margin-bottom-large" style="margin: auto;padding:5px; font-size: large;"><span>Find more
                    about me</span></div>
                <a href="https://www.linkedin.com/in/nabin-bagale-b6433399" target="_blank" rel="noopener noreferrer">
                  <svg xmlns="http://www.w3.org/2000/svg" width="56" height="56" fill="blue" class="bi bi-linkedin"
                    viewBox="0 0 16 16">
                    <path
                      d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854V1.146zm4.943 12.248V6.169H2.542v7.225h2.401zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248-.822 0-1.359.54-1.359 1.248 0 .694.521 1.248 1.327 1.248h.016zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016a5.54 5.54 0 0 1 .016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225h2.4z" />
                  </svg> </a>

                <a href="https://github.com/nabinelnino" target="_blank" rel="noopener noreferrer"
                  style="padding: 10px; margin: auto;"><svg xmlns="http://www.w3.org/2000/svg" width="56" height="56"
                    fill="black" class="bi bi-github" viewBox="0 0 16 16">
                    <path
                      d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" />
                  </svg>
                </a>
              </ul>
            </div>
        </div>
        <div class="col-xs-12 col-sm-7 col-md-8 wow fadeInRight animated" data-wow-delay=".5s">
          <div class="container right">
            <button type="button" class="btn btn-primary position-relative" style="font-size:x-large">
              Machine Learning Intern | Montreal, QC, Canada
              <span class="position-absolute top-0 start-100 translate-middle badge rounded-pill bg-danger">

                <span class="visually-hidden" style="font-size: large;">Feb 2020 - Present

                </span>
              </span>
            </button>

            <ul style="font-size: large; padding: auto; margin:10pt">
              <li>Developing CNN and RNN based pipeline for classifying facial emotions of patients during<br> a video
                conference.
              </li>
              <li>Working on an emotion classification algorithm to identify emotions from audio data.<br> Also, explore
                analytics tools to generate
                results in the plots and gather insight from data.</li>
              <b style="font-size:x-large; color:blueviolet ">Tools :</b> Jupyter Notebook, VS Code, Google Colab, MS
              Excel, FastAPI,<br> Trello, MS Word, Swagger <br>
              <b style="font-size:x-large; color:blueviolet ">Concepts:</b> Object detection and localization, Image
              Classification,<br> LSTM, Audio Feature extraction


            </ul>
            <button type="button" class="btn btn-primary position-relative" style="font-size:large">
              Data Engineer | Silicon Soft Nepal| Kathmandu, Nepal
              <span class="position-absolute top-0 start-100 translate-middle badge rounded-pill bg-danger">

                <span class="visually-hidden" style="font-size: large;"> Apr 2017 - Feb 2018
                </span>
              </span>
            </button>

            <ul style="font-size: large; padding: auto; margin:10pt">
              <li>Created and maintained data pipeline architecture.

              </li>
              <li>Built infrastructure required for optimal extraction, transformation, and loading of the data
              </li>
              <li>Extracted data from multiple data sources to provide relevant insights to meet
                <br>functional/non-functional business
                requirements
              </li>
              <li>Identified data anomalies and provided exceptional reports to the clients
              </li>
              <li>Worked with stakeholders and team members to create key performance indicators for the dashboard
              </li>
              <li>Wrote scripts to gather and analyze the data</li>
              <b style="font-size:x-large; color:blueviolet ">Tools :</b> S3, RDS, Trello, MS Excel, JIRA, Confluence,
              Swagger <br>
              <b style="font-size:x-large; color:blueviolet ">Languages:</b> SQL, Python, R

            </ul>
            <button type="button" class="btn btn-primary position-relative" style="font-size:large">
              Application and Database Developer | Inficare Pvt. Ltd. | Kathmandu, Nepal

              <span class="position-absolute top-0 start-100 translate-middle badge rounded-pill bg-danger">

                <span class="visually-hidden" style="font-size: small;"> Mar 2018 - Dec 2020
                </span>
              </span>
            </button>

            <ul style="font-size: large; padding: auto; margin:10pt">

              <li>Designed and created four onsite databases, maintained, and reconfigured more than 10 <br>
                existing
                databases and enhanced processing time by up to 20%.</li>
              <li>Worked as a software developer to develop Banking software and Entire web package for <br> different
                Municipal’s office. These systems are now running around 20 Municipalities and <br>
                more than 10
                Banks in Nepal.</li>
              <li>Contributed to each project delivery phase including analysis, development, test, and <br> deployment
                in
                different roles.
              </li>
              <b style="font-size:x-large; color:blueviolet ">Tools :</b> JIRA, GIT, MS Excel <br>
              <b style="font-size:x-large; color:blueviolet ">Languages:</b> ASP.NET/ASP.NET CORE, Angular JS,
              JQuery,SQL, JSON

            </ul>


          </div>
          <div class="container">

          </div>
        </div>
      </div>
    </div>
    <!-- =============== container end =============== -->
  </section>
  <!-- =============== how it works =============== -->
  <section id="Projects" class="parallax">
    <!-- =============== container =============== -->
    <div class="container">
      <span class="angle2"></span>
      <span class="angle"></span>
      <div class="row">

        <div class="col-xs-12 col-sm-12 col-md-12 wow bounceIn animated headding" data-wow-delay=".5s">
          <h2>Projects <span></span></h2>

          <p style="font-size:large;text-align:justify">
            <b>This is the part of the final year capstone project. In this project we’ll learn how to create an ML model for audio emotion detection from audio file. The audio files are in google drive. 
              Our task here will be the audio data classification.</b>
              <br>
              <br>
              <b>Dataset Description</b><br>
              <a href="https://zenodo.org/record/1188976#.YmLX5drMLIX" target="_blank"
              rel="noopener noreferrer">RADVESS</a> and <a
              href="https://tspace.library.utoronto.ca/handle/1807/24487" target="_blank"
              rel="noopener noreferrer">TESS</a>
              <br>
              <br>
              <b>Project Pipeline</b>
              Digital signal processing is the hot topic in the field of Machine learning recently. We can see a lot of research on emotion detection from video or from images and we can even get a lot of pretrained model for this. However, there is still lack of research and work in the field of Speech Emotion Recognization (SER). 
              <br>
              <br>
              Since the project is a classification problem, Convolution Neural Network seems the obvious choice, and we also built Random forest model, Multilayer perceptron but they underperformed with very low accuracies which could not pass the test while predicting the right emotions.
              <br>
              <br>
              Finally, build a recurrent neural network, namely, LSTM and model is then able to predict emotion form audio file with accuracy of more than 80%.
              <br>
              <b> This is our overall project pipeline</b><br>
              <img src="img/pp.PNG" class="img-fluid" alt="Responsive image"><br>
              <br>
              To generate the overall emotion from the recording, the system will create a temporary .wav file containing the input audio signals, preprocess it, and present the distribution of the emotion found in speech. The system will automatically generate emotion from audio file in every 10 seconds. While continuous speech is being delivered, the accrual process will continue to happen.  And at the end of the session, a summery is presented, keeping track of the mean values of all the emotions identified during the session, this process summery is shown in the Figure below. 
              <br>
              <img src="img/pp.gif" class="img-fluid" alt="Responsive image"><br>
              <br>
          </p>
        </div>



      </div>
    </div>
  </section>
  <!-- BLOGS -->
  <section id="Blogs" class="parallax">
    <div class="container">
      <span class="angle2"></span>
      <span class="angle"></span>
      <div class="row">
        <div class="col-xs-12 col-sm-12 col-md-12 wow bounceIn animated headding" data-wow-delay=".5s">
          <br>
          <br>
          <h1>Blog Posts</h1>
          <h2><a class="page-scroll" href="#Blogs1">Feature extraction from Audio signal for Machine learning model </a></h2>
          <svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" fill="currentColor" class="bi bi-stopwatch" viewBox="0 0 16 16">
            <path d="M8.5 5.6a.5.5 0 1 0-1 0v2.9h-3a.5.5 0 0 0 0 1H8a.5.5 0 0 0 .5-.5V5.6z"/>
            <path d="M6.5 1A.5.5 0 0 1 7 .5h2a.5.5 0 0 1 0 1v.57c1.36.196 2.594.78 3.584 1.64a.715.715 0 0 1 .012-.013l.354-.354-.354-.353a.5.5 0 0 1 .707-.708l1.414 1.415a.5.5 0 1 1-.707.707l-.353-.354-.354.354a.512.512 0 0 1-.013.012A7 7 0 1 1 7 2.071V1.5a.5.5 0 0 1-.5-.5zM8 3a6 6 0 1 0 .001 12A6 6 0 0 0 8 3z"/>
          </svg> 5 Minutes Read
          <h2><a class="page-scroll" href="#Blogs2">Which model to consider while getting emotions form audio data.</a></h2>
          <svg xmlns="http://www.w3.org/2000/svg" width="30" height="30" fill="currentColor" class="bi bi-stopwatch" viewBox="0 0 16 16">
            <path d="M8.5 5.6a.5.5 0 1 0-1 0v2.9h-3a.5.5 0 0 0 0 1H8a.5.5 0 0 0 .5-.5V5.6z"/>
            <path d="M6.5 1A.5.5 0 0 1 7 .5h2a.5.5 0 0 1 0 1v.57c1.36.196 2.594.78 3.584 1.64a.715.715 0 0 1 .012-.013l.354-.354-.354-.353a.5.5 0 0 1 .707-.708l1.414 1.415a.5.5 0 1 1-.707.707l-.353-.354-.354.354a.512.512 0 0 1-.013.012A7 7 0 1 1 7 2.071V1.5a.5.5 0 0 1-.5-.5zM8 3a6 6 0 1 0 .001 12A6 6 0 0 0 8 3z"/>
          </svg> 5 Minutes Read
         <h2> <a class="page-scroll" href="https://www.linkedin.com/in/nabin-bagale-b6433399" target="_blank" rel="noopener noreferrer">Linkdin</a></h2>
        </div>

        
        </div>
        <div class="col-xs-12 col-sm-12 col-md-12">

          <h3>Audio file overview</h3>
        </div>

      </div>
  </section>




  <section id="Blogs1" class="parallax">
    <!-- =============== container =============== -->
    <div class="container">
      <span class="angle2"></span>
      <span class="angle"></span>
      <div class="row">

        <div class="col-xs-12 col-sm-12 col-md-12 wow bounceIn animated headding" data-wow-delay=".5s">
          <br><br>
          <h2> Blog Part 1: Feature extraction from Audio signal for Machine learning model <span></span></h2>
          <p style="font-size:large">In the first part of this article series, I will talk about all you need to know
            before getting started with
            the audio data analysis and extract necessary features from a sound/audio file using python and
            Librosa- a python package that makes the analysis of audio files incredibly easy and straight forward. </p>
        </div>

        <div class="col-xs-12 col-sm-12 col-md-12">
          <div class="row">
            <div class="col-xs-10 col-sm-10 col-md-10 wow bounceIn animated headding" data-wow-delay=".5s">
              <h3>Audio file overview</h3>
              <p style="text-align:justify">The sound excerpts are digital audio files in .wav format. A digital sound
                wave is sampled at discrete
                intervals known as sampling rate (typically 44.1kHz for CD-quality audio, to which 44,100 samples are
                taken per second.
                <br><br>
                Next, we are goingto combine two different dataset which includes voice recording and respective
                labels:<b> Happy, sad, calm, angry, neutral, disgust etc.</b>
                the dataset I used are
                <a href="https://zenodo.org/record/1188976#.YmLX5drMLIX" target="_blank"
                  rel="noopener noreferrer">RADVESS</a> and <a
                  href="https://tspace.library.utoronto.ca/handle/1807/24487" target="_blank"
                  rel="noopener noreferrer">TESS</a>
                Each audio file was approximately 3 seconds long. I have used. Audio recordings will be trimmed to
                remove silences both at the start and at the end, various signal processing techniques,
                such as normalization, noise reduction, and transformation were used. <br>
                <img src="img/blog11.PNG" class="img-fluid" alt="Responsive image">
              <h4> Waveform of pure audio pre and post data cleaning</h4>
              <img src="img/blog12.PNG" class="img-fluid" alt="Responsive image">

              </p>
              <h3> Feature Selection</h3>
              <p style="text-align:justify"> Feature extraction from audio data is very challenging and the right
                feature for our context should
                be carefully chosen. It is essential to convert audio data into time domain feature and frequency domain
                feature
                to extract emotion from speech for various machine learning model.
                In order to complete this project, we gonna take mainly three audio features into consideration, namely,
                Mel-Frequency Cepstrum (MFCC), Zero Crossing Rate (ZCR), and Energy in terms of Root mean square value
                (RMS).
                <br>
                It has been suggested that audio features can be categorized into two major groups, namely time-domain
                features and frequency-domain features. Short term energy of the signal, Zero crossing rate (ZCR),
                energy level are part of the Time domain feature for our work. similarly, Spectrograms, Mel-Frequency
                Cepstral Coefficient (MFCCs) features as a part of Frequency domain features.
                <br>
              </p>
              <h4> Now let's get brief idea about MFCC and ZCR Feature of audio</h4>
              <h4>Mel-Frequency Cepstrum (MFCC)</h4>
              <p style="text-align:justify">By converting an audio signal through a series of steps to mimic the
                cochlea, Mel-Frequency Cepstrum represents the short-term power spectrum of sound. The audio signal is
                cut into short frames to ensure the stationarity of the audio signal. </p>
              <h4>Zero-crossing rate</h4>
              <p style="text-align:justify">The zero-crossing rate is the rate of sign-changes along a signal, i.e., the
                rate at which the signal changes from positive to zero to negative or from negative to zero to positive.
              </p>
              <h4> Now, we gonna combine all features into single array to represent one audio file to single
                representations </h4><br>
              <img src="img/blog13.PNG" class="img-fluid" alt="Responsive image">
              <p style="text-align:justify ;font-size:large">In the next blog post, you will see how this extracted
                features will be taken and passed into Machine learning model to classify the emotions from the given
                speech.</p>
            </div>
          </div>
        </div>

      </div>
    </div>
  
    <!-- =============== container end =============== -->
  </section>

  <!-- BLOG POST 2 -->

  <section id="Blogs2" class="parallax">
    <!-- =============== container =============== -->
    <div class="container">
      <span class="angle2"></span>
      <span class="angle"></span>
      <div class="row">

        <div class="col-xs-12 col-sm-12 col-md-12 wow bounceIn animated headding" data-wow-delay=".5s">
          <br><br>
          <h2> Blog Part 2: Which model to consider while getting emotions form audio data. <span></span></h2>
          <p style="font-size:large;text-align: justify;">This blog aims to investigate and implement Recurrent neural network algorithm 
            that will analyze an audio data and present emotion associated with this data. 
            In previous blog, I have covered what are the features to consider for model training.
             Here in this post, I am going to explain which model performs well on our data and what model does horribly wrong.
             <br>
             I have started with Convolution Neural Network (CNN) as a baseline model. 
             The Fast Fourier Transformation (FFT) representation of audio wave is fed into the sequential convolutional neural network (CNN). 
             As the validation score is low, I couldn’t move forward with this model.
             <br>
             As part of the transfer learning, I have used Resnet50 (Residual Network) model. 
             You might wonder how would audio data be trained on transfer learning? As transfer learning is only used for image data. 
             Don’t worry,<br>
             
            I have an answer for this… The generated Mel-spectrogram of the audio signal (which i covered in first part)  formed an array, by utilizing this array
              I have converted these signals into an Image having a 3-D array of size (224,224,3)
              with three channels that is Red, Green, and Blue. In this fashion, all labelled audio data is converted into images 
              and then passed into Resnet50 model. The observed validation and test accuracy of the model is much higher than baseline model, 
              however, we still have a room for improvement. <br>
              <b>Now, let’s think about another model.</b><br>
              <img src="img/thinking.gif" class="img-fluid" alt="Responsive image" height="400" width="400"><br>
             <b> Well… during the process of feature engineering, have you noticed one thing? What could be that one thing? </b>
             <b>Wait, I’ll say….. </b><br>
             We  could treat the extracted audio feature through librosa as a time series data.
              When it comes to the time series data analysis the Recurrent neural network works well. <br>
              The Long Short-Term Memory (LSTM) network is a type of Recurrent Neural Network, capable of learning order dependence in sequence prediction problems and 
              that train on the given output and try to predict result on the unseen data. Unlike traditional neural network, 
              LSTM keep the previous context of the given input and they try to classify given audio based on understanding of the previous 
              context so LSTM would come handy in this case. <br>
              <br>
              <b>Now, let’s try if LSTM performs well or not in our data.</b><br>
              The input feature of the model would be Energy – Root Mean Square (RMS), Zero Crossed Rate (ZCR), 
              and Mel-Frequency Cepstral Coefficients (MFCCs), note that all features have to combined into one to get a single array for each audio file.
               After running 400 epochs the train accuracy was 82%, which is pretty well in compared to previous model, so I decided to use this model 
               as a final model for emotion classification of the audio data. 
              Click here to view the complete model and it’s summery stat.
              <br>
              <b> The following chart shows the validation and Test accuracy of each model </b><br>
              <img src="img/blog21.PNG" class="img-fluid" alt="Responsive image" >
              <br>
              <b>From this plot we could conclude that LSTM is the best model for our case </b>
              <br>
              <b>The Model accuracy and model loss is shown below </b><br>
              <br>
              <img src="img/accuracy.PNG" class="img-fluid" alt="Responsive image" >

          </p>
        </div>

       

      </div>
    </div>
  
    <!-- =============== container end =============== -->
  </section>




  <!-- Footer -->
  <footer id="footer">
    <!-- =============== container =============== -->
    <div class="container">
      <div class="row">
        <div class="col-xs-12 col-sm-12 col-md-12">

          <!-- <ul class="social-links">
						<li><a class="wow fadeInUp animated" href="index.html#" style="visibility: visible; animation-name: fadeInUp;"><i class="fa fa-linkdin"></i></a></li>
						<li><a data-wow-delay=".1s" class="wow fadeInUp animated" href="index.html#" style="visibility: visible; animation-delay: 0.1s; animation-name: fadeInUp;"><i class="fa fa-linkdin"></i></a></li>
						<li><a data-wow-delay=".2s" class="wow fadeInUp animated" href="index.html#" style="visibility: visible; animation-delay: 0.2s; animation-name: fadeInUp;"><i class="fa fa-google-plus"></i></a></li>
						<li><a data-wow-delay=".4s" class="wow fadeInUp animated" href="index.html#" style="visibility: visible; animation-delay: 0.4s; animation-name: fadeInUp;"><i class="fa fa-pinterest"></i></a></li>
						<li><a data-wow-delay=".5s" class="wow fadeInUp animated" href="index.html#" style="visibility: visible; animation-delay: 0.5s; animation-name: fadeInUp;"><i class="fa fa-envelope"></i></a></li>
					</ul> -->

          <p class="copyright">
            &copy; 2022 Nabin
          </p>

        </div>
      </div>
    </div><!-- =============== container end =============== -->
  </footer>
  <!-- =============== jQuery =============== -->
  <script src="js/jquery.js"></script>
  <!-- =============== Bootstrap Core JavaScript =============== -->
  <script src="js/bootstrap.min.js"></script>
  <!-- =============== Plugin JavaScript =============== -->
  <script src="js/jquery.easing.min.js"></script>
  <script src="js/jquery.fittext.js"></script>
  <script src="js/wow.min.js"></script>
  <!-- =============== Custom Theme JavaScript =============== -->
  <script src="js/creative.js"></script>
  <!-- =============== owl carousel =============== -->
  <script src="owl-carousel/owl.carousel.js"></script>
  <script>
    $(document).ready(function () {
      $("#owl-demo").owlCarousel({
        autoPlay: 3000,
        items: 3,
        itemsDesktop: [1199, 3],
        itemsDesktopSmall: [979, 3]
      });

    });
  </script>
</body>

</html></html>
